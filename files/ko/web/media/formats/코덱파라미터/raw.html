<div>{{QuickLinksWithSubpages("/en-US/docs/Web/Media")}}</div>

<p>기본적으로, <code>video/mp4</code>, <code>audio/mpeg</code> 처럼 {{Glossary("MIME")}} 타입을 통해 미디어 파일 포맷을 명시할 수 있습니다. 하지만 많은 미디어 타입들이-특히 비디오 트랙을 지원하는 경우-가지고 있는 데이터 포맷에 대해 더 상세하고 정확하게 명시할 수 있습니다. 예를들어 <a href="/en-US/docs/Web/Media/Formats/Containers#MP4">MPEG-4</a> 비디오라고 해서 MIME 타입을 <code>video/mp4</code>만 명시한다면 정확히 어떤 미디어를 가지고 있는 지 아무 정보도 알 수 없습니다.</p>

<p>때문에 MIME 타입에 추가로 미디어 콘텐츠를 기술하기 위해 <code>codecs</code> 파라미터가 추가되었습니다. 이를 통해 컨테이너 특화된 정보를 제공할 수 있게 되었습니다 이 정보에는 비디오 코덱의 프로파일, 오디오 트랙 타입 등을 추가할 수 있습니다.</p>

<p><span class="seoSummary">이 가이드 문서는 단순히 컨테이너 타입 명시를 넘어 <code>codecs</code> 파라미터의 문법과 MIME 타입에 비디오/오디오 콘텐츠에 대한 상세 정보를 기술하는 방법에 대해 설명합니다.</span></p>

<h2 id="일반_문법">일반 문법</h2>

<p>기본적인 MIME 미디어 타입 표현은 미디어 타입(<code>audio</code>, <code>video</code>, 등)으로 시작하며, 슬래쉬 문자 (<code>/</code>) 후 미디어를 포함하고 있는 컨테이너 포맷이름으로 이어집니다:</p>

<dl>
 <dt><code>audio/mpeg</code></dt>
 <dd>MP3 같은 <a href="/en-US/docs/Web/Media/Formats/Containers#MPEG">MPEG</a> 파일 타입의 오디오 파일입니다.</dd>
 <dt><code>video/ogg</code></dt>
 <dd><a href="/en-US/docs/Web/Media/Formats/Containers#Ogg">Ogg</a> 파일 타입의 비디오 파일입니다.</dd>
 <dt><code>video/mp4</code></dt>
 <dd><a href="/en-US/docs/Web/Media/Formats/Containers#MP4">MPEG-4</a> 파일 타입을 사용하는 비디오입니다.</dd>
 <dt><code>video/quicktime</code></dt>
 <dd>애플 <a href="/en-US/docs/Web/Media/Formats/Containers#QuickTime">QuickTime</a> 포맷을 사용하는 비디오입니다. 다른 곳에서 서술되어 있듯이, 한때는 웹에서 널리 쓰여지던 형식이었지만 현재는 플러그인이 필요하여 더 이상 사용하지 않는 타입입니다.</dd>
</dl>

<p>위 MIME 타입은 아직 모호한 표현입니다. 각 파일 타입들은 많은 수의 코덱을 지원하며 코덱은 각기 프로파일, 레벨과 같은 설정 인자들을 가지고 있습니다. 그래서 <code>codecs</code> 파라미터를 추가하여 명시할 수 있습니다.</p>

<p>세미콜론 (<code>;</code>)을 붙이고 <code>codecs=</code> 으로 시작하는 문자열을 덧붙여 콘텐츠의 포맷을 서술할 수 있습니다. 일부 미디어 타입은 사용하는 코덱 이름만 명시 가능할 수 있고 다른 미디어 타입은 코덱에 관한 다양한 인자를 기술할 수 있는 경우도 있습니다. 콤마로 구분하여 여러 코덱을 기술할 수도 있습니다.</p>

<dl>
 <dt><code>audio/ogg; codecs=vorbis</code></dt>
 <dd><a href="/en-US/docs/Web/Media/Formats/Audio_codecs#Vorbis">Vorbis</a> 오디오 트랙을 포함하는 <a href="/en-US/docs/Web/Media/Formats/Containers#Ogg">Ogg</a> 컨테이너 파일입니다.</dd>
 <dt><code>video/webm; codecs="vp8, vorbis"</code></dt>
 <dd><a href="/en-US/docs/Web/Media/Formats/Video_codecs#VP8">VP8</a> 비디오와 <a href="/en-US/docs/Web/Media/Formats/Audio_codecs#Vorbis">Vorbis</a> 오디오를 포함하는 <a href="/en-US/docs/Web/Media/Formats/Containers#WebM">WebM</a> 컨테이너 파일입니다.</dd>
 <dt><code>video/mp4; codecs="avc1.4d002a"</code></dt>
 <dd><a href="/en-US/docs/Web/Media/Formats/Video_codecs#AVC_(H.264)">AVC</a> (H.264) 코덱에 Main Profile, Level 4.2을 가지는 <a href="/en-US/docs/Web/Media/Formats/Containers#MP4">MPEG-4</a> 컨테이너 파일입니다.</dd>
</dl>

<p>코덱의 속성 중 하나라도 퍼센트-인코딩이 필요한 특수문자{{RFC(2231, "MIME Parameter Value and Encoded Word Extensions", 4)}}를 사용하는 경우 MIME 타입을 기술하는 문자열의 <code>codecs</code> 파라미터를 <code>codecs*</code> (애스터리크(<code>*</code>) 추가됨에 유의)로 변경해야 합니다. JavaScript {{jsxref("Global_Objects/encodeURI", "encodeURI()")}} function으로 파라미터 목록을 인코딩할 수 있습니다; 반대로 {{jsxref("Global_Objects/decodeURI", "decodeURI()")}}를 통해 기인코딩된 파라미터 리스트를 디코딩할 수 있습니다.</p>

<div class="blockIndicator note">
<p><code>codecs</code> 파라미터를 사용한다면, 파일 콘텐츠가 사용한 모든 코덱을 목록에 명시해야합니다. 목록에 파일이 사용하고 있지 않은 코덱을 명시하는 것도 가능합니다.</p>
</div>

<h2 id="컨테이너별_코덱_옵션">컨테이너별 코덱 옵션</h2>

<p>아래 컨테이너들은 <code>codecs</code> 파라미터에 확장 옵션을 지원합니다:</p>

<div class="index">
<ul>
 <li>{{anch("ISO-BMFF", "3GP")}}</li>
 <li>{{anch("AV1")}}</li>
 <li>{{anch("ISO-BMFF", "ISO BMFF")}}</li>
 <li>{{anch("ISO-BMFF", "MPEG-4")}}</li>
 <li>{{anch("ISO-BMFF", "QuickTime")}}</li>
 <li>{{anch("WebM")}}</li>
</ul>
</div>

<p>링크를 클릭하면 동일한 섹션으로 이동할텐데요; 위 미디어 타입들은 모두 ISO Base Media File Format (ISO BMFF)를 기반하고 있어, 동일한 문법을 공유하기 때문입니다.</p>

<h3 id="AV1">AV1</h3>

<p>AV1의 <code>codecs</code> 문법은<a href="https://aomediacodec.github.io/av1-isobmff">AV1 Codec ISO Media File Format Binding</a> 스펙 문서의, 섹션 5: <a href="https://aomediacodec.github.io/av1-isobmff/#codecsparam">Codecs Parameter String</a>에 정의되어 있습니다.</p>

<pre>av01.P.LLT.DD[.M[.CCC[.cp[.tc[.mc[.F]]]]]]</pre>

<p>아래 표에서 코덱 파라미터 문자열 구성요소에 대해 자세히 설명하고 있습니다. 각 요소들은 고정된 개수의 문자로 되어 있으며;고정 길이보다 짧은 경우 앞에 0을 붙여서 맞춰야 합니다..</p>

<table class="standard-table">
 <caption>AV1 코덱 파라미터 문자열 요소</caption>
 <thead>
  <tr>
   <th scope="col">요소</th>
   <th scope="col">내용</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td><code>P</code></td>
   <td>
    <p>한자리 숫자 프로파일 번호:</p>

    <table class="standard-table">
     <caption>AV1 프로파일 번호</caption>
     <thead>
      <tr>
       <th scope="col">프로파일 번호</th>
       <th scope="col">설명</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>0</td>
       <td>"Main" 프로파일; YUV 4:2:0/모노크롬 크로마 서브샘플링 및 8/10 비트 색 깊이 지원.</td>
      </tr>
      <tr>
       <td>1</td>
       <td>"High" 프로파일 4:4:4 크로마 서브샘플링 추가 지원.</td>
      </tr>
      <tr>
       <td>2</td>
       <td>"Professional" 프로파일, 4:2:2 크로마 서브샘플링 및 12 비트 색 깊이 추가 지원</td>
      </tr>
     </tbody>
    </table>
   </td>
  </tr>
  <tr>
   <td><code>LL</code></td>
   <td>두자리 숫자 레벨 번호,  X.Y 형태의 레벨 포맷으로 변환 됨, <code>X = 2 + (LL &gt;&gt; 2)</code>, <code>Y = LL &amp; 3</code>. 자세한 내용은 AV1 스펙 문서의 <a href="https://aomediacodec.github.io/av1-spec/#levels">Appendix A, section 3</a> 참조.</td>
  </tr>
  <tr>
   <td><code>T</code></td>
   <td>한자리 문자 티어 표시. Main 티어라면 (<code>seq_tier</code> equals 0), 문자는 <code>M</code>. High 티어는 (<code>seq_tier</code> is 1) <code>H</code>. High 티어는 4.0 이상 레벨에서만 가능합니다.</td>
  </tr>
  <tr>
   <td><code>DD</code></td>
   <td>두자리 숫자 색 깊이. 8, 10, 12 중 하나여야 하며; 프로파일과 다른 속성에서 지원 가능한 값이여야 합니다.</td>
  </tr>
  <tr>
   <td><code>M</code></td>
   <td>한자리 숫자 모노크롬 플래그; 0인 경우 비디오는 U, V, Y 성분을 모두 가지고 있습니다. 아닌 경우 전체 비디오 데이터는 Y(휘도) 성분 뿐으로 모노크롬 이미지를 가집니다. 자세한 내용은 {{SectionOnPage("/en-US/docs/Web/Media/Formats/Video_concepts", "YUV")}}를 참조하여 YUV 컬러 시스템이 어떻게 동작하는지 알아보세요. 기본 값은 0 (모노크롬 아님)입니다.</td>
  </tr>
  <tr>
   <td><code>CCC</code></td>
   <td>
    <p><code>CCC</code> 는 세자리 숫자로 크로마 서브샘플링을 표기합니다. 첫번째 숫자는 <code>subsampling_x</code>, 두 번째 숫자는 <code>subsampling_y</code>. 둘다 1인경우, 세번째 값은 <code>chroma_sample_position</code>; 아닌 경우 세번째 값은 항상 0입니다. <code>M</code> 값과 더불어 크로마 서브샘플링 포맷을 구성하는 요소입니다:</p>

    <table class="standard-table">
     <caption>크로마 서브샘플링 결정 방식</caption>
     <thead>
      <tr>
       <th scope="col">subsampling_x</th>
       <th scope="col">subsampling_y</th>
       <th scope="col">Monochrome flag</th>
       <th scope="col">Chroma subsampling format</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>0</td>
       <td>0</td>
       <td>0</td>
       <td>YUV 4:4:4</td>
      </tr>
      <tr>
       <td>1</td>
       <td>0</td>
       <td>0</td>
       <td>YUV 4:2:2</td>
      </tr>
      <tr>
       <td>1</td>
       <td>1</td>
       <td>0</td>
       <td>YUV 4:2:0</td>
      </tr>
      <tr>
       <td>1</td>
       <td>1</td>
       <td>1</td>
       <td>YUV 4:0:0 (Monochrome)</td>
      </tr>
     </tbody>
    </table>

    <p><code>CCC</code>의 세번째 값은 크로마 샘플 위치(chroma sample position)로, 0은 위치를 알 수 없으며 디코딩 시 개별적으로 제공해야 함을 의미합니다; 1은 샘플이 (0, 0) 휘도 샘플과 동일한 수평선상에 있음을 의미합니다; 2는 샘플이 (0, 0) 휘도 샘플과 동일한 위치에 있음을 의미합니다.</p>

    <p>기본 값은 <code>110</code> (4:2:0 크로마 서브샘플링)입니다.</p>
   </td>
  </tr>
  <tr>
   <td><code>cp</code></td>
   <td>두자리 숫자 <code>color_primaries</code> 값은 미디어의 색 공간을 표시합니다. 예를 들어 HDR 비디오에서 사용하는 BT.2020/BT.2100 색 공간은 <code>09</code>입니다. 자세한 정보-그 외의 색 공간 값을 포함하여-는 AV1 스펙 문서의 <a href="https://aomediacodec.github.io/av1-spec/#color-config-semantics">Color config semantics section</a> 를 참조하세요. 기본값은 <code>01</code> (ITU-R BT.709)입니다.</td>
  </tr>
  <tr>
   <td><code>tc</code></td>
   <td>두자리 숫자 <code>transfer_characteristics</code> 값. 이 값은 소스에서 디스플레이로 감마를 매핑하는 함수(기술적인 용어로 "opto-electrical transfer function"라 표현)를 정의합니다. 예를 들어 10-bit BT.2020는 <code>14</code>입니다. 기본 값은 <code>01</code> (ITU-R BT.709)입니다.</td>
  </tr>
  <tr>
   <td><code>mc</code></td>
   <td>두자리 숫자 <code>matrix_coefficients</code> 상수는 RGB 컬러 채널을 휘도/색차 신호로 변환 시 사용할 계수 행렬을 선택합니다. 예를 들어 BT.709의 표준 계수 값은 <code>01</code>로 표현합니다. 기본 값은 <code>01</code> (ITU-R BT.709)입니다.</td>
  </tr>
  <tr>
   <td><code>F</code></td>
   <td>한자리 숫자로 색상이 가능한 모든 범위를 표현해야 할지(<code>1</code>), 지정한 색 설정에 의해 적합하다고 여겨지는 범위로 제한하여 표현(<strong>studio swing representation</strong>이라 표현)해야 할지를 나타내는 값입니다. 기본 값은 0 (studio swing representation 적용)입니다.</td>
  </tr>
 </tbody>
</table>

<p><code>M</code> (모노크롬 플래그)이후의 요소는 모두 비필수입니다; 어느 곳에서부터나 생략할 수 있습니다 (하지만 임의의 중간 요소를 생략할 수는 없습니다). 기본 값은 위 표에 서술하였습니다. AV1 코덱 문자열 예시는 아래와 같습니다:</p>

<dl>
 <dt><code>av01.2.15M.10.0.100.09.16.09.0</code></dt>
 <dd>AV1 Professional 프로파일, 레벨 5.3, Main 티어, 10 비트 색 깊이, 4:2:2 크로마 서브샘플링 ITU-R BT.2100 색 공간, 색 전환 YCbCr 색상 행렬. Studio swing representation 적용.</dd>
 <dt><code>av01.0.15M.10</code></dt>
 <dd>AV1 Main 프로파일, 레벨 5.3, Main 티어, 10 비트 색 깊이. 나머지 요소는 기본 값 사용: 4:2:0 크로마 서브 샘플링, BT.709 색 공간, 색 전환, 계수 행렬 사용. Studio swing representation.</dd>
</dl>

<h3 id="ISO_Base_Media_File_Format_MP4_QuickTime_and_3GP"><a id="ISO-BMFF" name="ISO-BMFF">ISO Base Media File Format: MP4, QuickTime, and 3GP</a></h3>

<p>모든 미디어 타입은 {{interwiki("wikipedia", "ISO Base Media File Format")}} (ISO BMFF)를 기반으로 하며 <code>codecs</code> 문법을 공유합니다. 이들 미디어 타입은 <a href="/en-US/docs/Web/Media/Formats/Containers#MP4">MPEG-4</a> (또 사실상 MPEG-4를 기반으로 하고 있으므로 <a href="/en-US/docs/Web/Media/Formats/Containers#QuickTime">QuickTime</a>도 포함)과 <a href="/en-US/docs/Web/Media/Formats/Containers#3GP">3GP</a>를 포함합니다. MIME 타입의 <code>codecs</code> 파라미터를 통해 아래와 같이 비디오/오디오 트랙 둘 다 기술할 수 있습니다.:</p>

<table class="standard-table">
 <caption>ISO BMFF codecs 파라미터를 지원하는 기본 MIME 타입</caption>
 <thead>
  <tr>
   <th scope="col">MIME 타입</th>
   <th scope="col">설명</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td><code>audio/3gpp</code></td>
   <td>3GP 오디오 ({{RFC(3839, "MIME Type Registrations for 3rd generation Partnership Project (3GP) Multimedia files")}})</td>
  </tr>
  <tr>
   <td><code>video/3gpp</code></td>
   <td>3GP 비디오 ({{RFC(3839, "MIME Type Registrations for 3rd generation Partnership Project (3GP) Multimedia files")}})</td>
  </tr>
  <tr>
   <td><code>audio/3gp2</code></td>
   <td>3GP2 오디오 ({{RFC(4393, "MIME Type Registrations for 3GPP2 Multimedia files")}})</td>
  </tr>
  <tr>
   <td><code>video/3gp2</code></td>
   <td>3GP2 비디오 ({{RFC(4393, "MIME Type Registrations for 3GPP2 Multimedia files")}})</td>
  </tr>
  <tr>
   <td><code>audio/mp4</code></td>
   <td>MP4 오디오 ({{RFC(4337, "MIME Type Registration for MPEG-4")}})</td>
  </tr>
  <tr>
   <td><code>video/mp4</code></td>
   <td>MP4 비디오 ({{RFC(4337, "MIME Type Registration for MPEG-4")}})</td>
  </tr>
  <tr>
   <td><code>application/mp4</code></td>
   <td>오디오/비디오가 아닌 MPEG-4 컨테이너 미디어</td>
  </tr>
 </tbody>
</table>

<p><code>codecs</code> 파라미티에는 간단하게 컨테이너 명(<code>3gp</code>, <code>mp4</code>, <code>quicktime</code>, etc.)만 기술할 수도 있으며 컨테이너 명에 코덱 이름 및 설정 값을 함께 기술할 수도 있습니다. 각 코덱 등은 온점(<code>.</code>)으로 구분된 요소를 다수 가질 수 있습니다.</p>

<p><code>codecs</code> 값의 문법은 코덱마다 다릅니다; 하지만 항상 4 글자 코덱 구분자와 온점(<code>.</code>)으로 시작하며 데이터 포맷을 기술하기 위핸 Object Type Indication (OTI) 형식의 문자열이 뒤따릅니다. 대부분의 코덱에서 OTI는 두자리 16진수로 되어 있지만 <a href="/en-US/docs/Web/Media/Formats/Video_codecs#AVC_(H.264)">AVC (H.264)</a>는 6자리 16진수로 구성되어 있습니다.</p>

<p>따라서 지원하는 코덱 문법은 아래와 유사합니다:</p>

<dl>
 <dt><code>cccc[.pp]*</code> (Generic ISO BMFF)</dt>
 <dd><code>cccc</code> 는 4 글자 코덱 ID이며  <code>pp</code>는 0~2자리 인코딩 된 문자입니다.</dd>
 <dt><code>mp4a.oo[.A]</code> (MPEG-4 audio)</dt>
 <dd><code>oo</code> 는 미디어 콘텐츠를 더 정확하게 기술하는 Object Type Indication 값이며 <code>A</code> 는 한자리 숫자<em>오디오</em> OTI입니다. OTI로 가능한 값은 MP4 Registration Authority 웹사이트의 <a href="http://mp4ra.org/#/object_types">Object Types page</a> 페이지에서 확인할 수 있습니다. 예를들어 MP4 파일의 Opus 오디오는 <code>mp4a.ad</code>로 기술합니다. 자세한 내용은 {{anch("MPEG-4 audio")}}를 참조하세요.</dd>
 <dt><code>mp4v.oo[.V]</code> (MPEG-4 video)</dt>
 <dd>마찬가지로 <code>oo</code> 는 미디어 콘텐츠를 명시하는 OTI 값이며, <code>V</code> 는 한자리 숫자 <em>비디오</em> OTI 값입니다.</dd>
 <dt><code>avc1.oo[.PPCCLL]</code> (AVC video)</dt>
 <dd>
 <p><code>oo</code> 는 콘텐츠를 명시하는 OTI 값이며, while <code>PPCCLL</code> 는 6자리 16진수로써 프로파일 넘버 (<code>PP</code>), 제약 플래그 (<code>CC</code>), 레벨 (<code>LL</code>)을 의미합니다. <code>PP</code>로 가능한 값은 {{anch("AVC profiles")}}를 참조하세요.</p>

 <p>제약 플래그는 1 비트 불리언 값이며, MSB는 flag 0(또는 일부에선 <code>constraint_set0_flag</code>)로 취급합니다. 그리고 이어지는 비트는 하나씩 번호가 높게 매겨집니다. 현재로썬 0부터 2번째 비트까지만 사용하며;나머지 5개의 비트는 <em>반드시</em> 0이어야합니다. 각 플래그의 의미는 사용하는 프로파일에 따라 달라집니다.</p>

 <p>레벨 값은 고정 소수점이므로 숫자 <code>14</code> (10진법 20) 은 레벨 2.0을 의미하며 <code>3D</code> (10진법 61) 은 레벨 6.1을 의미합니다. 일반적으로 레벨 숫자가 높을 수록 스트림 대역폭이 높아 더 큰 크기의 비디오를 지원할 수 있습니다.</p>
 </dd>
</dl>

<h4 id="AVC_프로파일">AVC 프로파일</h4>

<p>아래의 AV 프로파일 넘버는 <code>codecs</code> 파라미터에서 사용하며 제약 요소 값은 <code>CC</code>로 사용할 수 있습니다.</p>

<table class="standard-table">
 <caption><code>codecs</code>  파라미터에서 AVC 프로파일과 제약 요건을 명세하기 위한 값</caption>
 <thead>
  <tr>
   <th scope="col">프로파일</th>
   <th scope="col">넘버(Hex)</th>
   <th scope="col">제약 (byte)</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td><strong>Constrained Baseline Profile (CBP)</strong><br>
    CBP는 리소스가 제약점이 있거나 재생이 원활하지 못해 발생하는 이상 요소들을 최소화 해야 하는 경우 주요한 해결책입니다.</td>
   <td><code>42</code></td>
   <td><code>40</code></td>
  </tr>
  <tr>
   <td><strong>Baseline Profile (BP)</strong><br>
    CBP와 유사하나 데이터 손실 방지와 복구 능력을 향상시킨 프로파일입니다.  CBP가 도입된 이후에는 이전만큼 널리 사용하고 있지는 않습니다. CBP 스트림은 모두 BP 스트림으로 간주할 수도 있습니다.</td>
   <td><code>42</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Extended Profile (XP)</strong><br>
    고효율 압축과 네트워크 전송시의 데이터 안정성, 스트림 스위칭을 고려한 프로파일입니다.</td>
   <td><code>58</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Main Profile (MP)</strong><br>
    MPEG-4 포맷으로 전송하는 디지털 표준 TV 방송에서 사용하는 프로파일입니다. 고선명 TV(HDV)에서는 <em>사용하지 않습니다</em>. 2004년 —HDTV에서 사용하기 위해— High Profile이 추가된 이후 중요도가 감소하였습니다.</td>
   <td><code>4D</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>High Profile (HiP)</strong><br>
    현재로써는 전파방송과 매체기반 HD 비디오에서 사용하는 주요 프로파일입니다. HD TV 방송과 블루레이 미디어에서 사용하고 있습니다.</td>
   <td><code>64</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Progressive High Profile (PHiP)</strong><br>
    필드 코딩 지원을 제거한 High Profile입니다.</td>
   <td><code>64</code></td>
   <td><code>08</code></td>
  </tr>
  <tr>
   <td><strong>Constrained High Profile</strong><br>
    양방향 예측 슬라이스("B-slices") 지원을 제거한 PHiP입니다.</td>
   <td><code>64</code></td>
   <td><code>0C</code></td>
  </tr>
  <tr>
   <td><strong>High 10 Profile (Hi10P)</strong><br>
    10 비트 컬러 모드 지원을 제거한 High Profile입니다.</td>
   <td><code>6E</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>High 4:2:2 Profile (Hi422P)</strong><br>
    Hi10P에 4:2:2 크로마 서브샘플링과 최대 10비트 컬러 모드 지원을 추가한 프로파일입니다.</td>
   <td><code>7A</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>High 4:4:4 Predictive Profile (Hi444PP)</strong><br>
    Hi422P 및 Hi444PP에 4:4:4 크로마 서브샘플링(색차 샘플링 소거 없음)을 추가 지원한 프로파일입니다. 또한 최대 14비트 컬러 샘플과 효율적인 무손실 지역 코딩을 추가하였습니다. 각 프레임을 3개의 분리된 컬러 평면(각 평면은 모노크롬 프레임형태로 저장됩니다)으로 인코딩할 수 있는 옵션입니다.</td>
   <td><code>F4</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>High 10 Intra Profile</strong><br>
    all-intra-frame에 High 10 제약이 걸린 프로파일입니다. 전문가 용 앱에 주로 쓰입니다.</td>
   <td><code>6E</code></td>
   <td><code>10</code></td>
  </tr>
  <tr>
   <td><strong>High 4:2:2 Intra Profile</strong><br>
    all-intra-frame에 Hi422를 적용한 프로파일입니다.</td>
   <td><code>7A</code></td>
   <td><code>10</code></td>
  </tr>
  <tr>
   <td><strong>High 4:4:4 Intra Profile</strong><br>
    all-intra-frame에 High 4:4:4 제약을 건 프로파일입니다.</td>
   <td><code>F4</code></td>
   <td><code>10</code></td>
  </tr>
  <tr>
   <td><strong>CAVLC 4:4:4 Intra Profile</strong><br>
    all-intra-frame에 High 4:4:4 제약, CAVLC 엔트로피 코딩만 사용하는 프로파일입니다.</td>
   <td><code>44</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Scalable Baseline Profile</strong><br>
    화상 회의, 감시 카메라 및 모바일 장치에서 쓰이는 프로파일로, {{interwiki("wikipedia", "SVC")}} Baseline Profile은 AVC의 Constrained Baseline profile에 기반하고 있습니다. 스트림의 베이스 레이어는 고품질로 제공되면서, 제약이 걸린 환경에서 대안이 될 수 있는 서브스트림을 다수 제공하는 방식입니다. 서브스트림은 해상도 감소, 낮은 프레임레이트, 압축률 저하 등을 조합하여 구성합니다.</td>
   <td><code>53</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Scalable Constrained Baseline Profile</strong><br>
    실시간 양방향 대화형 어플리케이션에서 주요 사용하는 프로파일입니다. WebRTC에서 아직 정식으로 지원하지는 않지만,  <a href="https://github.com/w3c/webrtc-svc">SVC를 활성화</a>하여 WebRTC AP 개발 모드에서 사용해 볼 수 있습니다.</td>
   <td><code>53</code></td>
   <td><code>04</code></td>
  </tr>
  <tr>
   <td><strong>Scalable High Profile</strong><br>
    방송 및 스트리밍 어플리케이션에서 주로 사용합니다. 베이스(또는 최고 품질) 레이어에는 AVC High Profile이 반드시 포함되어야 합니다.</td>
   <td><code>56</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Scalable Constrained High Profile</strong><br>
    실시간 통신을 위한 Scalable High Profile의 서브셋 프로파일입니다.</td>
   <td><code>56</code></td>
   <td><code>04</code></td>
  </tr>
  <tr>
   <td><strong>Scalable High Intra Profile</strong><br>
    비디오 제작 어플리케이션을 위한 all-intra-frame 프로파일입니다.</td>
   <td><code>56</code></td>
   <td><code>20</code></td>
  </tr>
  <tr>
   <td><strong>Stereo High Profile</strong><br>
    양안 렌더링을 통한 스테레오스코픽(stereoscopic) 비디오를 지원하는 프로파일입니다. 양안 영상이 아닌 경우 High profile과 동일합니다.</td>
   <td><code>80</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Multiview High Profile</strong><br>
    시간 및 MVC inter-view 예측을 통한 2개 이상의 뷰를 지원하는 프로파일입니다.. <em>Does not support</em> field pictures 필드 픽쳐 또는 매크로블록-어댑티브한 frame-field 코딩을 <em>지원하지 않습니다</em>.</td>
   <td><code>76</code></td>
   <td><code>00</code></td>
  </tr>
  <tr>
   <td><strong>Multiview Depth High Profile</strong><br>
    Based on the High Profile, to which the main substream must adhere. The remaining substreams must match the Stereo High Profile.</td>
   <td><code>8A</code></td>
   <td><code>00</code></td>
  </tr>
 </tbody>
</table>

<h4 id="MPEG-4_audio">MPEG-4 audio</h4>

<p>When the value of an entry in the <code>codecs</code> 목록의 값 항목이 <code>mp4a</code>로 시작한다면, 문법은 아래와 같아야 합니다:</p>

<pre>mp4a.oo[.A]</pre>

<p><code>oo</code> 는 두자리 16진수 Object Type Indication으로 미디어에 사용된 코덱 클래스를 표시합니다. OTI 값은 <a href="http://mp4ra.org/">MP4 Registration Authority</a>에서 규정하고 있으며 <a href="http://mp4ra.org/#/object_types">list of the possible OTI values</a>에서 가용한 값을 확인할 수 있습니다. 특수한 값인 <code>40</code>; 이는 미디어가 MPEG-4 audio(ISO/IEC 14496 Part 3)임을 나타냅니다.. In order to be more specific still, a third component—the Audio Object Type—is added for OTI <code>40</code> to narrow the type down to a specific subtype of MPEG-4.</p>

<p>The Audio Object Type is specified as a one or two digit <em>decimal</em> value (unlike most other values in the <code>codecs</code> parameter, which use hexadecimal). For example, MPEG-4's AAC-LC has an audio object type number of <code>2</code>, so the full <code>codecs</code> value representing AAC-LC is <code>mp4a.40.2</code>.</p>

<p>Thus, ER AAC LC, whose Audio Object Type is 17, can be represented using the full <code>codecs</code> value <code>mp4a.40.17</code>. Single digit values can be given either as one digit (which is the best choice, since it will be the most broadly compatible) or with a leading zero padding it to two digits, such as <code>mp4a.40.02</code>.</p>

<div class="blockIndicator note">
<p><strong>Note:</strong> The specification originally mandated that the Audio Object Type number in the third component be only one decimal digit. However, amendments to the specification over time extended the range of these values well beyond one decimal digit, so now the third parameter may be either one or two digits. Padding values below 10 with a leading <code>0</code> is optional. Older implementations of MPEG-4 codecs may not support two-digit values, however, so using a single digit when possible will maximize compatibility.</p>
</div>

<p>The Audio Object Types are defined in ISO/IEC 14496-3 subpart 1, section 1.5.1. The table below provides a basic list of the Audio Object Types and in the case of the more common object ypes provides a list of the profiles supporting it, but you should refer to the specification for details if you need to know more about the inner workings of any given MPEG-4 audio type.</p>

<table class="standard-table">
 <caption>MPEG-4 audio object types</caption>
 <thead>
  <tr>
   <th scope="col">ID</th>
   <th scope="col">Audio Object Type</th>
   <th scope="col">Profile support</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td><code>0</code></td>
   <td>NULL</td>
   <td></td>
  </tr>
  <tr>
   <td><code>1</code></td>
   <td>AAC Main</td>
   <td>Main</td>
  </tr>
  <tr>
   <td><code>2</code></td>
   <td>AAC LC (Low Complexity)</td>
   <td>Main, Scalable, HQ, LD v2, AAC, HE-AAC, HE-AAC v2</td>
  </tr>
  <tr>
   <td><code>3</code></td>
   <td>AAC SSR (Scalable Sampling Rate)</td>
   <td>Main</td>
  </tr>
  <tr>
   <td><code>4</code></td>
   <td>AAC LTP (Long Term Prediction)</td>
   <td>Main, Scalable, HQ</td>
  </tr>
  <tr>
   <td><code>5</code></td>
   <td>SBR (Spectral Band Replication)</td>
   <td>HE-AAC, HE-AAC v2</td>
  </tr>
  <tr>
   <td><code>6</code></td>
   <td>AAC Scalable</td>
   <td>Main, Scalable, HQ</td>
  </tr>
  <tr>
   <td><code>7</code></td>
   <td>TwinVQ (Coding for ultra-low bit rates)</td>
   <td>Main, Scalable</td>
  </tr>
  <tr>
   <td><code>8</code></td>
   <td>CELP (Code-Excited Linear Prediction)</td>
   <td>Main, Scalable, Speech, HQ, LD</td>
  </tr>
  <tr>
   <td><code>9</code></td>
   <td>HVXC (Harmonic Vector Excitation Coding)</td>
   <td>Main, Scalable, Speech, LD</td>
  </tr>
  <tr>
   <td><code>10</code> – <code>11</code></td>
   <td><em>Reserved</em></td>
   <td></td>
  </tr>
  <tr>
   <td><code>12</code></td>
   <td>TTSI (Text to Speech Interface)</td>
   <td>Main, Scalable, Speech, Synthetic, LD</td>
  </tr>
  <tr>
   <td><code>13</code></td>
   <td>Main Synthetic</td>
   <td>Main, Synthetic</td>
  </tr>
  <tr>
   <td><code>14</code></td>
   <td>Wavetable Synthesis</td>
   <td></td>
  </tr>
  <tr>
   <td><code>15</code></td>
   <td>General MIDI</td>
   <td></td>
  </tr>
  <tr>
   <td><code>16</code></td>
   <td>Algorithmic Synthesis and Audio Effects</td>
   <td></td>
  </tr>
  <tr>
   <td><code>17</code></td>
   <td>ER AAC LC (Error Resilient AAC Low-Complexity)</td>
   <td>HQ, Mobile Internetworking</td>
  </tr>
  <tr>
   <td><code>18</code></td>
   <td><em>Reserved</em></td>
   <td></td>
  </tr>
  <tr>
   <td><code>19</code></td>
   <td>ER AAC LTP (Error Resilient AAC Long Term Prediction)</td>
   <td>HQ</td>
  </tr>
  <tr>
   <td><code>20</code></td>
   <td>ER AAC Scalable (Error Resilient AAC Scalable)</td>
   <td>Mobile Internetworking</td>
  </tr>
  <tr>
   <td><code>21</code></td>
   <td>ER TwinVQ (Error Resilient TwinVQ)</td>
   <td>Mobile Internetworking</td>
  </tr>
  <tr>
   <td><code>22</code></td>
   <td>ER BSAC (Error Reslient Bit-Sliced Arithmetic Coding)</td>
   <td>Mobile Internetworking</td>
  </tr>
  <tr>
   <td><code>23</code></td>
   <td>ER AAC LD (Error Resilient AAC Low-Delay; used for two-way communiation)</td>
   <td>LD, Mobile Internetworking</td>
  </tr>
  <tr>
   <td><code>24</code></td>
   <td>ER CELP (Error Resilient Code-Excited Linear Prediction)</td>
   <td>HQ, LD</td>
  </tr>
  <tr>
   <td><code>25</code></td>
   <td>ER HVXC (Error Resilient Harmonic Vector Excitation Coding)</td>
   <td>LD</td>
  </tr>
  <tr>
   <td><code>26</code></td>
   <td>ER HILN (Error Resilient Harmonic and Individual Line plus Noise)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>27</code></td>
   <td>ER Parametric (Error Resilient Parametric)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>28</code></td>
   <td>SSC (Sinusoidal Coding)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>29</code></td>
   <td>PS (Parametric Stereo)</td>
   <td>HE-AAC v2</td>
  </tr>
  <tr>
   <td><code>30</code></td>
   <td>MPEG Surround</td>
   <td></td>
  </tr>
  <tr>
   <td><code>31</code></td>
   <td><em>Escape</em></td>
   <td></td>
  </tr>
  <tr>
   <td><code>32</code></td>
   <td>MPEG-1 Layer-1</td>
   <td></td>
  </tr>
  <tr>
   <td><code>33</code></td>
   <td>MPEG-1 Layer-2 (MP2)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>34</code></td>
   <td>MPEG-1 Layer-3 (MP3)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>35</code></td>
   <td>DST (Direct Stream Transfer)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>36</code></td>
   <td>ALS (Audio Lossless)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>37</code></td>
   <td>SLS (Scalable Lossless)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>38</code></td>
   <td>SLS Non-core (Scalable Lossless Non-core)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>39</code></td>
   <td>ER AAC ELD (Error Resilient AAC Enhanced Low Delay)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>40</code></td>
   <td>SMR Simple (Symbolic Music Representation Simple)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>41</code></td>
   <td>SMR Main (Symbolic Music Representation Main)</td>
   <td></td>
  </tr>
  <tr>
   <td><code>42</code></td>
   <td><em>Reserved</em></td>
   <td></td>
  </tr>
  <tr>
   <td><code>43</code></td>
   <td>SAOC (Spatial Audio Object Coding)<sup><a href="#audio-object-types-foot-1">[1]</a></sup></td>
   <td></td>
  </tr>
  <tr>
   <td><code>44</code></td>
   <td>LD MPEG Surround (Low Delay MPEG Surround)<sup><a href="#audio-object-types-foot-1">[1]</a></sup></td>
   <td></td>
  </tr>
  <tr>
   <td><code>45</code> and up</td>
   <td><em>Reserved</em></td>
   <td></td>
  </tr>
 </tbody>
</table>

<p><a name="audio-object-types-foot-1">[1]</a> SAOC and LD MPEG Surround are defined in <a href="https://www.iso.org/standard/54838.html">ISO/IEC 14496-3:2009/Amd.2:2010(E)</a>.</p>

<h3 id="WebM">WebM</h3>

<p>The basic form for a WebM <code>codecs</code> parameter is to simply list one or more of the four WebM codecs by name, separated by commas. The table below shows some examples:</p>

<table class="standard-table">
 <caption>Examples of classic WebM MIME types with <code>codecs</code> parameter</caption>
 <thead>
  <tr>
   <th scope="col">MIME type</th>
   <th scope="col">Description</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td><code>video/webm;codecs="vp8"</code></td>
   <td>A WebM video with VP8 video in it; no audio is specified.</td>
  </tr>
  <tr>
   <td><code>video/webm;codecs="vp9"</code></td>
   <td>A WebM video with VP9 video in it.</td>
  </tr>
  <tr>
   <td><code>audio/webm;codecs="vorbis"</code></td>
   <td>Vorbis audio in a WebM container.</td>
  </tr>
  <tr>
   <td><code>audio/webm;codecs="opus"</code></td>
   <td>Opus audio in a WebM container.</td>
  </tr>
  <tr>
   <td><code>video/webm;codecs="vp8,vorbis"</code></td>
   <td>A WebM container with VP8 video and Vorbis audio.</td>
  </tr>
  <tr>
   <td><code>video/webm;codecs="vp9,opus"</code></td>
   <td>A WebM container with VP9 video and Opus audio.</td>
  </tr>
 </tbody>
</table>

<p>The strings <code>vp8.0</code> and <code>vp9.0</code> also work, but are not recommended.</p>

<h4 id="ISO_Base_Media_File_Format_syntax">ISO Base Media File Format syntax</h4>

<p>As part of a move toward a standardized and powerful format for the <code>codecs</code> parameter, WebM is moving toward describing <em>video</em> content using a syntax based on that defined by the <a href="#ISO-BMFF">ISO Base Media File Format</a>. This syntax is defined in <a href="https://www.webmproject.org/vp9/mp4">VP Codec ISO Media File Format Binding</a>, in the section <a href="https://www.webmproject.org/vp9/mp4/#codecs-parameter-string">Codecs Parameter String</a>. The audio codec continues to be indicated as either <code>vorbis</code> or <code>opus</code>.</p>

<p>In this format, the <code>codecs</code> parameter's value begins with a four-character code identifying the codec being used in the container, which is then followed by a series of period (<code>.</code>) separated two-digit values.</p>

<pre>cccc.PP.LL.DD.CC[.cp[.tc[.mc[.FF]]]]</pre>

<p>The first five components are required; everything from <code>cp</code> (color primaries) onward is optional; you can stop including components at any point from then onward. Each of these components is described in the following table. Following the table are some examples.</p>

<table class="standard-table">
 <caption>WebM codecs parameter components</caption>
 <thead>
  <tr>
   <th scope="col">Component</th>
   <th scope="col">Details</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td><code>cccc</code></td>
   <td>
    <p>A four-character code indicating which indicates which of the possible codecs is being described. Potential values are:</p>

    <table class="standard-table">
     <caption>Four-character codes for WebM-supported codecs</caption>
     <thead>
      <tr>
       <th scope="col">Four-character code</th>
       <th scope="col">Codec</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td><code>vp08</code></td>
       <td>VP8</td>
      </tr>
      <tr>
       <td><code>vp09</code></td>
       <td>VP9</td>
      </tr>
      <tr>
       <td><code>vp10</code></td>
       <td>VP10</td>
      </tr>
     </tbody>
    </table>
   </td>
  </tr>
  <tr>
   <td><code>PP</code></td>
   <td>
    <p>The two-digit profile number, padded with leading zeroes if necessary to be exactly two digits.</p>

    <table class="standard-table">
     <caption>WebM profile numbers</caption>
     <thead>
      <tr>
       <th scope="col">Profile</th>
       <th scope="col">Description</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td><code>00</code></td>
       <td>Only 4:2:0 (chroma subsampled both horizontally and vertically). Allows only 8 bits per color component.</td>
      </tr>
      <tr>
       <td><code>01</code></td>
       <td>All chroma subsampling formats are allowed. Allows only 8 bits per color component.</td>
      </tr>
      <tr>
       <td><code>02</code></td>
       <td>Only 4:2:0 (chroma subsampled both horizontally and vertically). Supports 8, 10, or 12 bits per color sample component.</td>
      </tr>
      <tr>
       <td><code>03</code></td>
       <td>All chroma subsampling formats are allowed. Supports 8, 10, or 12 bits per color sample component.</td>
      </tr>
     </tbody>
    </table>
   </td>
  </tr>
  <tr>
   <td><code>LL</code></td>
   <td>The two-digit level number. The level number is a fixed-point notation, where the first digit is the ones digit, and the second digit represents tenths. For example, level 3 is <code>30</code> and level 6.1 is <code>61</code>.</td>
  </tr>
  <tr>
   <td><code>DD</code></td>
   <td>The bit depth of the luma and color component values; permitted values are 8, 10, and 12.</td>
  </tr>
  <tr>
   <td><code>CC</code></td>
   <td>
    <p>A two-digit value indicating which chroma subsampling format to use. The following table lists permitted values; see {{SectionOnPage("en-US/docs/Web/Media/Formats/Video_concepts", "Chroma subsampling")}} for additional information about this topic and others.</p>

    <table class="standard-table">
     <caption>WebM chroma subsampling identifiers</caption>
     <thead>
      <tr>
       <th scope="col">Value</th>
       <th scope="col">Chroma subsampling format</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td><code>00</code></td>
       <td>4:2:0 with the chroma samples sited interstitially between the pixels</td>
      </tr>
      <tr>
       <td><code>01</code></td>
       <td>4:2:0 chroma subsampling with the samples colocated with luma (0, 0)</td>
      </tr>
      <tr>
       <td><code>02</code></td>
       <td>4:2:2 chroma subsampling (4 out of each 4 horizontal pixels' luminance are used)</td>
      </tr>
      <tr>
       <td><code>03</code></td>
       <td>4:4:4 chroma subsampling (every pixel's luminance and chrominance are both retained)</td>
      </tr>
      <tr>
       <td><code>04</code></td>
       <td><em>Reserved</em></td>
      </tr>
     </tbody>
    </table>
   </td>
  </tr>
  <tr>
   <td><code>cp</code></td>
   <td>
    <p>A two-digit integer specifying which of the color primaries from Section 8.1 of the <a href="https://www.itu.int/rec/T-REC-H.273/en">ISO/IEC 23001-8:2016</a> standard. This component, and every component after it, is optional.</p>

    <p>The possible values of the color primaries component are:</p>

    <table class="standard-table">
     <caption>ISO/IEC Color primary identifiers</caption>
     <thead>
      <tr>
       <th scope="col">Value</th>
       <th scope="col">Details</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td><code>00</code></td>
       <td><em>Reserved for future use by ITU or ISO/IEC</em></td>
      </tr>
      <tr>
       <td><code>01</code></td>
       <td>BT.709, sRGB, sYCC. BT.709 is the standard for high definition (HD) television; sRGB is the most common color space used for computer displays. Broadcast BT.709 uses 8-bit color depth with the legal range being from 16 (black) to 235 (white).</td>
      </tr>
      <tr>
       <td><code>02</code></td>
       <td>Image characteristics are unknown, or are to be determined by the application</td>
      </tr>
      <tr>
       <td><code>03</code></td>
       <td><em>Reserved for future use by ITU or ISO/IEC</em></td>
      </tr>
      <tr>
       <td><code>04</code></td>
       <td>BT.470 System M, NTSC (standard definition television in the United States)</td>
      </tr>
      <tr>
       <td><code>05</code></td>
       <td>BT.470 System B, G; BT.601; BT.1358 625; BT.1700 625 PAL and 625 SECAM</td>
      </tr>
      <tr>
       <td><code>06</code></td>
       <td>BT.601 525; BT.1358 525 or 625; BT.1700 NTSC; SMPTE 170M. <em>Functionally identical to <code>7</code>.</em></td>
      </tr>
      <tr>
       <td><code>70</code></td>
       <td>{{Glossary("SMPTE")}} 240M (historical). <em>Functionally identical to <code>6</code>.</em></td>
      </tr>
      <tr>
       <td><code>08</code></td>
       <td>Generic film</td>
      </tr>
      <tr>
       <td><code>09</code></td>
       <td>BT.2020; BT.2100. Used for ultra-high definition (4K) High Dynamic Range (HDR) video, these have a very wide color gamut and support 10-bit and 12-bit color component depths.</td>
      </tr>
      <tr>
       <td><code>10</code></td>
       <td>SMPTE ST 428 (D-Cinema Distribution Master: Image characteristics). Defines the uncompressed image characteristics for DCDM.</td>
      </tr>
      <tr>
       <td><code>11</code></td>
       <td>SMPTE RP 431 (D-Cinema Quality: Reference projector and environment). Describes the reference projector and environment conditions that provide a consistent film presentation experience.</td>
      </tr>
      <tr>
       <td><code>12</code></td>
       <td>SMPTE EG 432 (Digital Source Processing: Color Processing for D-Cinema). Engineering guideline making color signal decoding recommendations for digital movies.</td>
      </tr>
      <tr>
       <td><code>13</code> – <code>21</code></td>
       <td><em>Reserved for future use by ITU-T or ISO/IEC</em></td>
      </tr>
      <tr>
       <td><code>22</code></td>
       <td>EBU Tech 3213-E</td>
      </tr>
      <tr>
       <td><code>23</code> – <code>255</code></td>
       <td><em>Reserved for future use by ITU-T or ISO/IEC</em></td>
      </tr>
     </tbody>
    </table>
   </td>
  </tr>
  <tr>
   <td><code>tc</code></td>
   <td>A two-digit integer indicating the <code>transferCharacteristics</code> for the video. This value is from Section 8.2 of <a href="https://www.itu.int/rec/T-REC-H.273/en">ISO/IEC 23001-8:2016</a>, and indicates the transfer characteristics to be used when adapting the decoded color to the render target.</td>
  </tr>
  <tr>
   <td><code>mc</code></td>
   <td>The two-digit value for the <code>matrixCoefficients</code> property. This value comes from the table in Section 8.3 of the <a href="https://www.itu.int/rec/T-REC-H.273/en">ISO/IEC 23001-8:2016</a> specification. This value indicates which set of coefficients to use when mapping from the native red, blue, and green primaries to the luma and chroma signals. These coefficients are in turn used with the equations found in that same section.</td>
  </tr>
  <tr>
   <td><code>FF</code></td>
   <td>Indicates whether to restrict the black level and color range of each color component to the legal range. For 8 bit color samples, the legal range is 16-235. A value of <code>00</code> indicates that these limitations should be enforced, while a value of <code>01</code> allows the full range of possible values for each component, even if the resulting color is out of bounds for the color system.</td>
  </tr>
 </tbody>
</table>

<h4 id="WebM_media_type_examples">WebM media type examples</h4>

<dl>
 <dt><code>video/webm;codecs="vp08.00.41.08,vorbis"</code></dt>
 <dd>VP8 video, profile 0 level 4.1, using 8-bit YUV with 4:2:0 chroma subsampling, using BT.709 color primaries, transfer function, and matrix coefficients, with the luminance and chroma values encoded within the legal ("studio") range. The video is Vorbis.</dd>
 <dt><code>video/webm;codecs="vp09.02.10.10.01.09.16.09.01,opus"</code></dt>
 <dd>VP9 video, profile 2 level 1.0, with 10-bit YUV content using 4:2:0 chroma subsampling, BT.2020 primaries, ST 2084 EOTF (HDR SMPTE), BT.2020 non-constant luminance color matrix, and full-range chroma and luma encoding. The audio is in Opus format.</dd>
</dl>

<h2 id="Using_the_codecs_parameter">Using the codecs parameter</h2>

<p>You can use the <code>codecs</code> parameter in a few situations. Firstly, you can use it with the {{HTMLElement("source")}} element when creating an {{HTMLElement("audio")}} or {{HTMLElement("video")}} element, in order to establish a group of options for the browser to choose from when selecting the format of the media to present to the user in the element.</p>

<p>You can also use the codecs parameter when specifying a MIME media type to the {{domxref("MediaSource.isTypeSupported()")}} method; this method returns a Boolean which indicates whether or not the media is likely to work on the current device.</p>

<h2 id="See_also">See also</h2>

<ul>
 <li><a href="/en-US/docs/Web/Media">Web media technologies</a></li>
 <li><a href="/en-US/docs/Web/Media/Formats">Guide to media types and formats on the web</a></li>
 <li><a href="/en-US/docs/Web/Media/Formats/Audio_codecs">Guide to audio codecs used on the web</a></li>
 <li><a href="/en-US/docs/Web/Media/Formats/Video_codecs">Guide to video codecs used on the web</a></li>
 <li><a href="/en-US/docs/Web/Media/Formats/WebRTC_codecs">Codecs used by WebRTC</a></li>
</ul>