<div>{{DefaultAPISidebar("Web Speech API")}}{{seecompattable}}</div>

<div class="summary">
<p>Web Speech API 使您能够将语音数据合并到 Web 应用程序中。 Web Speech API 有两个部分：SpeechSynthesis 语音合成 （文本到语音 TTS）和 SpeechRecognition  语音识别（异步语音识别）。</p>
</div>

<h2 id="Web_Speech_的概念及用法">Web Speech 的概念及用法</h2>

<p>Web Speech API 使 Web 应用能够处理语音数据，该项 API 包含以下两个部分：</p>

<ul>
 <li>语音识别通过 {{domxref("SpeechRecognition")}} 接口进行访问，它提供了识别从音频输入（通常是设备默认的语音识别服务）中识别语音情景的能力。一般来说，你将使用该接口的构造函数来构造一个新的 {{domxref("SpeechRecognition")}} 对象，该对象包含了一些列有效的对象处理函数来检测识别设备麦克风中的语音输入。{{domxref("SpeechGrammar")}} 接口则表示了你应用中想要识别的特定文法。文法则通过 <a href="http://www.w3.org/TR/jsgf/">JSpeech Grammar Format</a> (<strong>JSGF</strong>.) 来定义。</li>
 <li>语音合成通过 {{domxref("SpeechSynthesis")}} 接口进行访问，它提供了文字到语音（TTS）的能力，这使得程序能够读出它们的文字内容（通常使用设备默认的语音合成器）。不同的声音类类型通过 {{domxref("SpeechSynthesisVoice")}} 对象进行表示，不同部分的文字则由 {{domxref("SpeechSynthesisUtterance")}} 对象来表示。你可以将它们传递给 {{domxref("SpeechSynthesis.speak()")}} 方法来产生语音。</li>
</ul>

<p>更多关于这些特性的细节请参考 <a href="/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API">Using the Web Speech API</a>。</p>

<h2 id="Web_Speech_的_API_接口">Web Speech 的 API 接口</h2>

<h3 id="语音识别"> 语音识别</h3>

<dl>
 <dt>{{domxref("SpeechRecognition")}}</dt>
 <dd>The controller interface for the recognition service; this also handles the {{domxref("SpeechRecognitionEvent")}} sent from the recognition service.</dd>
 <dt>{{domxref("SpeechRecognitionAlternative")}}</dt>
 <dd>Represents a single word that has been recognised by the speech recognition service.</dd>
 <dt>{{domxref("SpeechRecognitionError")}}</dt>
 <dd>Represents error messages from the recognition service.</dd>
 <dt>{{domxref("SpeechRecognitionEvent")}}</dt>
 <dd>The event object for the {{event("result")}} and {{event("nomatch")}} events, and contains all the data associated with an interim or final speech recognition result.</dd>
 <dt>{{domxref("SpeechGrammar")}}</dt>
 <dd>The words or patterns of words that we want the recognition service to recognize.</dd>
 <dt>{{domxref("SpeechGrammarList")}}</dt>
 <dd>Represents a list of {{domxref("SpeechGrammar")}} objects.</dd>
 <dt>{{domxref("SpeechRecognitionResult")}}</dt>
 <dd>Represents a single recognition match, which may contain multiple {{domxref("SpeechRecognitionAlternative")}} objects.</dd>
 <dt>{{domxref("SpeechRecognitionResultList")}}</dt>
 <dd>Represents a list of {{domxref("SpeechRecognitionResult")}} objects, or a single one if results are being captured in {{domxref("SpeechRecognition.continuous","continuous")}} mode.</dd>
</dl>

<h3 id="语音合成">语音合成</h3>

<dl>
 <dt>{{domxref("SpeechSynthesis")}}</dt>
 <dd>The controller interface for the speech service; this can be used to retrieve information about the synthesis voices available on the device, start and pause speech, and other commands besides.</dd>
 <dt>{{domxref("SpeechSynthesisErrorEvent")}}</dt>
 <dd>Contains information about any errors that occur while processing {{domxref("SpeechSynthesisUtterance")}} objects in the speech service.</dd>
 <dt>{{domxref("SpeechSynthesisEvent")}}</dt>
 <dd>Contains information about the current state of {{domxref("SpeechSynthesisUtterance")}} objects that have been processed in the speech service.</dd>
 <dt>{{domxref("SpeechSynthesisUtterance")}}</dt>
 <dd>Represents a speech request. It contains the content the speech service should read and information about how to read it (e.g. language, pitch and volume.)</dd>
</dl>

<dl>
 <dt>{{domxref("SpeechSynthesisVoice")}}</dt>
 <dd>Represents a voice that the system supports. Every <code>SpeechSynthesisVoice</code> has its own relative speech service including information about language, name and URI.</dd>
 <dt>{{domxref("Window.speechSynthesis")}}</dt>
 <dd>Specced out as part of a <code>[NoInterfaceObject]</code> interface called <code>SpeechSynthesisGetter</code>, and Implemented by the <code>Window</code> object, the <code>speechSynthesis</code> property provides access to the {{domxref("SpeechSynthesis")}} controller, and therefore the entry point to speech synthesis functionality.</dd>
</dl>

<h2 id="示例">示例</h2>

<p>GitHub 上的 <a href="https://github.com/mdn/web-speech-api/">Web Speech API repo</a> 的示例程序展示了语音识别及合成。</p>

<h2 id="规范">规范</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">规范</th>
   <th scope="col">状态</th>
   <th scope="col">描述</th>
  </tr>
  <tr>
   <td>{{SpecName('Web Speech API')}}</td>
   <td>{{Spec2('Web Speech API')}}</td>
   <td>原始定义</td>
  </tr>
 </tbody>
</table>

<h2 id="浏览器兼容性">浏览器兼容性</h2>

<div>{{Compat("api.SpeechRecognition", 0)}}</div>

<div>{{Compat("api.SpeechSynthesis", 0)}}</div>

<h2 id="相关链接">相关链接</h2>

<ul>
 <li><a href="/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API">Using the Web Speech API</a></li>
 <li><a href="http://www.sitepoint.com/talking-web-pages-and-the-speech-synthesis-api/">SitePoint article</a></li>
 <li><a href="http://updates.html5rocks.com/2014/01/Web-apps-that-talk---Introduction-to-the-Speech-Synthesis-API">HTML5Rocks article</a></li>
 <li><a href="http://aurelio.audero.it/demo/speech-synthesis-api-demo.html">Demo</a> [aurelio.audero.it]</li>
</ul>